{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b692c73",
   "metadata": {},
   "source": [
    "# Using Redis and OpenAI to chat with PDF documents\n",
    "\n",
    "This notebook demonstrates how to use RedisAI and (Azure) OpenAI to chat with PDF documents. The PDF included is\n",
    "a informational brochure about the Chevy Colorado pickup truck.\n",
    "\n",
    "In this notebook, we will use LLamaIndex to chunk, vectorize, and store the PDF document in Redis as vectors\n",
    "alongside associated text. The query interface provided by LLamaIndex will be used to search for relevant\n",
    "information given queries from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949e6cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redis\n",
      "  Using cached redis-4.5.5-py3-none-any.whl (240 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-3.10.0-py3-none-any.whl (255 kB)\n",
      "     ------------------------------------ 255.9/255.9 kB 982.5 kB/s eta 0:00:00\n",
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (0.4.0)\n",
      "Collecting llama_index==0.6.8\n",
      "  Using cached llama_index-0.6.8-py3-none-any.whl (389 kB)\n",
      "Requirement already satisfied: openai>=0.26.4 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.6.8) (0.27.8)\n",
      "Requirement already satisfied: requests<2.30.0 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.6.8) (2.28.1)\n",
      "Collecting tenacity<9.0.0,>=8.2.0\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.6.8) (1.5.3)\n",
      "Collecting langchain>=0.0.154\n",
      "  Downloading langchain-0.0.207-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 5.2 MB/s eta 0:00:00\n",
      "Collecting dataclasses-json\n",
      "  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.6.8) (1.23.5)\n",
      "Requirement already satisfied: async-timeout>=4.0.2 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from redis) (4.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (2022.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2\n",
      "  Using cached openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain>=0.0.154->llama_index==0.6.8) (2.8.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain>=0.0.154->llama_index==0.6.8) (3.8.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain>=0.0.154->llama_index==0.6.8) (1.4.39)\n",
      "Collecting pydantic<2,>=1\n",
      "  Downloading pydantic-1.10.9-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 10.4 MB/s eta 0:00:00\n",
      "Collecting langchainplus-sdk>=0.0.13\n",
      "  Downloading langchainplus_sdk-0.0.16-py3-none-any.whl (24 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Using cached marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.1/49.1 kB ? eta 0:00:00\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<2.30.0->llama_index==0.6.8) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<2.30.0->llama_index==0.6.8) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<2.30.0->llama_index==0.6.8) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<2.30.0->llama_index==0.6.8) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas->llama_index==0.6.8) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas->llama_index==0.6.8) (2.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama_index==0.6.8) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama_index==0.6.8) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama_index==0.6.8) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama_index==0.6.8) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama_index==0.6.8) (1.3.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama_index==0.6.8) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.154->llama_index==0.6.8) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\huolu\\appdata\\local\\anaconda3\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json->llama_index==0.6.8) (0.4.3)\n",
      "Installing collected packages: typing-inspect, tenacity, redis, python-dotenv, PyPDF2, pypdf, pydantic, marshmallow, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, dataclasses-json, langchain, llama_index\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "Successfully installed PyPDF2-3.0.1 dataclasses-json-0.5.8 langchain-0.0.207 langchainplus-sdk-0.0.16 llama_index-0.6.8 marshmallow-3.19.0 marshmallow-enum-1.5.1 openapi-schema-pydantic-1.2.4 pydantic-1.10.9 pypdf-3.10.0 python-dotenv-1.0.0 redis-4.5.5 tenacity-8.2.2 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the requirements\n",
    "%pip install redis pypdf PyPDF2 python-dotenv transformers tiktoken llama_index==0.6.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47264e32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:23.988789Z",
     "start_time": "2023-02-10T12:20:23.967877Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "import openai\n",
    "from langchain.llms import AzureOpenAI, OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from llama_index.vector_stores import RedisVectorStore\n",
    "from llama_index import LangchainEmbedding\n",
    "from llama_index import (\n",
    "    GPTVectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor,\n",
    "    PromptHelper,\n",
    "    ServiceContext,\n",
    "    StorageContext\n",
    ")\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO) # logging.DEBUG for more verbose output\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2014a346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://myopenairesourcehuolu.openai.azure.com/\n",
      "redisdemo621.westus.redisenterprise.cache.azure.net\n",
      "2022-12-01\n"
     ]
    }
   ],
   "source": [
    "# load the .env file in the parent directory into the current environment\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv('./.env'))\n",
    "print(os.getenv(\"AZURE_OPENAI_API_BASE\"))\n",
    "print(os.getenv(\"REDIS_ADDRESS\"))\n",
    "print(os.getenv(\"OPENAI_API_VERSION\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ad91218",
   "metadata": {},
   "source": [
    "# Azure OpenAI and OpenAI\n",
    "\n",
    "The notebook allows the user two choose between using the OpenAI and Azure OpenAI endpoints. Make sure to follow the instructions in the README and set the .env correctly according to whichever API you are using. \n",
    "\n",
    "NOTE: ONLY ONE API CAN BE USED AT A TIME."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0023333d",
   "metadata": {},
   "source": [
    "## Azure OpenAI \n",
    "\n",
    "Here we setup the AzureOpenAI models and API keys that we set by reading from the environment above. The ``PromptHelper`` sets the parameters for the OpenAI model. The classes defined here are used together to provide a QnA interface between the user and the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a77108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup Llama Index to use Azure OpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Get the OpenAI model names ex. \"text-embedding-ada-002\"\n",
    "embedding_model = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "text_model = os.getenv(\"OPENAI_TEXT_MODEL\")\n",
    "\n",
    "print(f\"Azure OpenAI Endpoint: {openai.api_base}\")\n",
    "print(f\"Using models: {embedding_model} and {text_model}\")\n",
    "\n",
    "# get the Azure Deployment name for the model\n",
    "embedding_model_deployment = os.getenv(\"AZURE_EMBED_MODEL_DEPLOYMENT_NAME\")\n",
    "text_model_deployment = os.getenv(\"AZURE_TEXT_MODEL_DEPLOYMENT_NAME\")\n",
    "\n",
    "print(f\"Using deployments: {embedding_model_deployment} and {text_model_deployment}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67d58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = AzureOpenAI(deployment_name=text_model_deployment, model_kwargs={\n",
    "    \"api_key\": openai.api_key,\n",
    "    \"api_base\": openai.api_base,\n",
    "    \"api_type\": openai.api_type,\n",
    "    \"api_version\": openai.api_version,\n",
    "})\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "embedding_llm = LangchainEmbedding(\n",
    "    OpenAIEmbeddings(\n",
    "        model=embedding_model,\n",
    "        deployment=embedding_model_deployment,\n",
    "        openai_api_key= openai.api_key,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_type=openai.api_type,\n",
    "        openai_api_version=openai.api_version,\n",
    "    ),\n",
    "    embed_batch_size=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59ff935d",
   "metadata": {},
   "source": [
    "### LLamaIndex\n",
    "\n",
    "[LlamaIndex](https://github.com/jerryjliu/llama_index) (GPT Index) is a project that provides a central interface to connect your LLM's with external data sources. It provides a simple interface to vectorize and store embeddings in Redis, create search indices using Redis, and perform vector search to find context for generative models like GPT.\n",
    "\n",
    "Here we will use it to load in the documents (Chevy Colorado Brochure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:30.175678Z",
     "start_time": "2023-02-10T12:20:30.172456Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader('./docs').load_data()\n",
    "print('Document ID:', documents[0].doc_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "697a59d2",
   "metadata": {},
   "source": [
    "Llamaindex also works with frameworks like langchain to make prompting and other aspects of a chat based application easier. Here we can use the ``PromptHelper`` class to help us generate prompts for the (Azure) OpenAI model. The will be off by default as it can be tricky to setup correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147e7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of output tokens\n",
    "num_output = int(os.getenv(\"OPENAI_MAX_TOKENS\"))\n",
    "# max LLM token input size\n",
    "max_input_size = int(os.getenv(\"CHUNK_SIZE\"))\n",
    "# set maximum chunk overlap\n",
    "max_chunk_overlap = int(os.getenv(\"CHUNK_OVERLAP\"))\n",
    "\n",
    "prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "132b7b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the service we will use to answer questions\n",
    "# if you executive the Azure OpenAI code above, your Azure Models and creds will be used and the same for OpenAI\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=llm_predictor,\n",
    "    embed_model=embedding_llm,\n",
    "#    prompt_helper=prompt_helper # uncomment to use prompt_helper.\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd270925",
   "metadata": {},
   "source": [
    "## Initialize Redis as a Vector Database\n",
    "\n",
    "Now we have our documents read in, we can initialize the ``RedisVectorStore``. This will allow us to store our vectors in Redis and create an index.\n",
    "\n",
    "The ``GPTVectorStoreIndex`` will then create the embeddings from the text chunks by calling out to OpenAI's API. The embeddings will be stored in Redis and an index will be created.\n",
    "\n",
    "NOTE: If you didn't set the ``OPENAI_API_KEY`` environment variable, you will get an error here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "788f73b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Redis address: redis://default:lLpd3J+k+384obzlVZRBs7QdqFYIOP1IW723+lRS6tY=@redisdemo621.westus.redisenterprise.cache.azure.net:10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_redis_conn_from_env(using_ssl=False):\n",
    "    start = \"rediss://\" if using_ssl else \"redis://\"\n",
    "    # if using RBAC\n",
    "    password = os.getenv(\"REDIS_PASSWORD\", None)\n",
    "    username = os.getenv(\"REDIS_USERNAME\", \"default\")\n",
    "    if password != None:\n",
    "        start += f\"{username}:{password}@\"\n",
    "\n",
    "    return start + f\"{os.getenv('REDIS_ADDRESS')}:{os.getenv('REDIS_PORT')}\"\n",
    "\n",
    "\n",
    "# make using_ssl=True to use SSL with ACRE\n",
    "redis_address = format_redis_conn_from_env(using_ssl=False)\n",
    "\n",
    "print(f\"Using Redis address: {redis_address}\")\n",
    "vector_store = RedisVectorStore(\n",
    "    index_name=\"chevy_docs\",\n",
    "    index_prefix=\"blog\",\n",
    "    redis_url=redis_address,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# access the underlying client in the RedisVectorStore implementation to ping the redis instance\n",
    "vector_store.client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba1558b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:33.735897Z",
     "start_time": "2023-02-10T12:20:30.404245Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Deleting index chevy_docs\n",
      "Deleting index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Creating index chevy_docs\n",
      "Creating index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Added 27 documents to index chevy_docs\n",
      "Added 27 documents to index chevy_docs\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 14521 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 14521 tokens\n"
     ]
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = GPTVectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04304299-fc3e-40a0-8600-f50c3292767e",
   "metadata": {},
   "source": [
    "## Start Querying information from the Document\n",
    "\n",
    "Now that we have our document stored in the index, we can ask questions against the index. The index will use the data stored in itself as the knowledge base for chatgpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35369eda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:51.328762Z",
     "start_time": "2023-02-10T12:20:33.822688Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Found 2 results for query with id ['blog_c35dfa95-6bdd-42f2-b785-ae49b7b82bb5', 'blog_6879b851-b3b7-4791-8db5-5d5102f52bb1']\n",
      "Found 2 results for query with id ['blog_c35dfa95-6bdd-42f2-b785-ae49b7b82bb5', 'blog_6879b851-b3b7-4791-8db5-5d5102f52bb1']\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 11 tokens\n",
      "> [retrieve] Total embedding token usage: 11 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1536 tokens\n",
      "> [get_response] Total LLM token usage: 1536 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "  The Chevrolet Colorado is available in four models: WT, LT, Z71, and ZR2. Each model offers\n",
      "different features, such as engine size, power-adjustable seats, and recovery hooks (4x4).\n",
      "Additionally, special editions of each model are available, such as the Z71 Midnight Edition, ZR2\n",
      "Bison Edition, ZR2 Dusk Special Edition, and ZR2 Midnight Special Edition.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What types of variants are available for the Chevrolet Colorado?\")\n",
    "print(\"\\n\", textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99212d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:21:10.337294Z",
     "start_time": "2023-02-10T12:20:51.338718Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Found 2 results for query with id ['blog_b7bfcb05-8fdd-4a29-853b-723b46972fef', 'blog_c35dfa95-6bdd-42f2-b785-ae49b7b82bb5']\n",
      "Found 2 results for query with id ['blog_b7bfcb05-8fdd-4a29-853b-723b46972fef', 'blog_c35dfa95-6bdd-42f2-b785-ae49b7b82bb5']\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 14 tokens\n",
      "> [retrieve] Total embedding token usage: 14 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1000 tokens\n",
      "> [get_response] Total LLM token usage: 1000 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "  The maximum towing capacity of the Chevy Colorado is 7,700 lbs. with the available GM-exclusive\n",
      "Duramax® 2.8L Turbo-Diesel engine when equipped with the Trailering Package, LT Convenience Package,\n",
      "and Safety Package.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the maximum towing capacity of the chevy colorado?\")\n",
    "print(\"\\n\", textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a028452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Found 2 results for query with id ['blog_8c2c602b-f396-40fc-a60f-38f293ef4b1e', 'blog_a36b73c6-182d-4cac-baed-579737d1ce28']\n",
      "Found 2 results for query with id ['blog_8c2c602b-f396-40fc-a60f-38f293ef4b1e', 'blog_a36b73c6-182d-4cac-baed-579737d1ce28']\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 16 tokens\n",
      "> [retrieve] Total embedding token usage: 16 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1803 tokens\n",
      "> [get_response] Total LLM token usage: 1803 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "  The main differences between the three engine types available for the Chevy Colorado are as\n",
      "follows:  1. 2.5L DOHC I-4: This engine offers 200 hp @ 6300 rpm, 191 lb.-ft. of torque @ 4400 rpm,\n",
      "Displacement of 2460 cc (150 cu. in.), Bore and stroke of 88 mm x 101 mm (3.46 in. x 3.97 in.),\n",
      "Compression ratio of 11.3:1, Max payload rating of 1,420 lbs., and Max trailering weight rating of\n",
      "3,500 lbs.  2. 3.6L DOHC V6: This engine offers 308 hp @ 6800 rpm, 275 lb.-ft. of torque @ 4000 rpm,\n",
      "Displacement of 3640 cc (222 cu. in.), Bore and stroke of 95 mm x 85.6 mm (3.74 in. x 3.37 in.),\n",
      "Compression ratio of 11.5:1, Max payload rating of 1,540 lbs., and Max trailering weight rating of\n",
      "7,000 lbs.  3. Duramax 2.8L Turbo-Diesel I-4: This engine offers 181 hp @ 3400 rpm, 369 lb.-ft. of\n",
      "torque\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What are the main differences between the three engine types available for the Chevy Colorado?\")\n",
    "print(\"\\n\", textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e73a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
